{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Problem Statement & Exploratory Data Analysis\n",
    "\n",
    "**Student Name:** [Your Name]\n",
    "\n",
    "**Dataset:** [Your Dataset Name]\n",
    "\n",
    "**Checkpoints:**\n",
    "- Checkpoint 1 (Due Feb 1): Sections 1-3\n",
    "- Checkpoint 2 (Due Feb 8): Sections 4-6\n",
    "\n",
    "---\n",
    "\n",
    "## Rules & Integrity\n",
    "\n",
    "1. **NO AI TOOLS**: You may **NOT** use ChatGPT, Claude, Gemini, GitHub Copilot, or any other AI assistant to generate code for this assignment. The goal is to build *your* fundamental skills. If you rely on AI now, the advanced topics later will be impossible.\n",
    "\n",
    "2. **Study Groups Encouraged**: You **ARE** encouraged to discuss ideas, share approaches, and explain concepts to your study group peers. Teaching others is the best way to learn! However, the code you submit must be **your own work**.\n",
    "\n",
    "3. **Use Your Resources**: You are free to use Google, StackOverflow, Pandas/Scikit-learn documentation, and your class notes.\n",
    "\n",
    "4. **Comment Your Code**: Include comments explaining *why* you're doing what you're doing. I want to see your thought process.\n",
    "\n",
    "5. **Resubmission**: You may submit this assignment multiple times for feedback before each checkpoint deadline.\n",
    "\n",
    "---\n",
    "\n",
    "## Important: Written Reflections\n",
    "\n",
    "Throughout this notebook, you'll see text cells asking you to explain your decisions, observations, and reasoning. **These written reflections are a critical part of your grade.** \n",
    "\n",
    "Don't just write one-word answers or skip these sections. Your reflections demonstrate:\n",
    "- Your understanding of the data science process\n",
    "- Your ability to communicate findings to stakeholders\n",
    "- Your critical thinking about data quality and feature importance\n",
    "\n",
    "Take time to write thoughtful, complete responses. This is what separates a good data scientist from someone who just runs code!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell first to import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# CHECKPOINT 1 (Due: Feb 1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Problem Statement\n",
    "\n",
    "### 1.1 What are you trying to predict?\n",
    "\n",
    "*Clearly state your target variable and what it represents.*\n",
    "\n",
    "**Your answer:**\n",
    "\n",
    "[The goal of this project is to predict the stage of Chronic Kidney Disease (CKD) for each patient using the medical features provided in the dataset. The CKD stage represents how well a patient’s kidneys are functioning based on their lab results and health indicators)\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Why does this prediction matter?\n",
    "\n",
    "*Who would care about this prediction? What decisions could be made with it?*\n",
    "\n",
    "**Your answer:**\n",
    "\n",
    "[Predicting the CKD stage is important because it helps determine how severe a patient’s kidney condition is. This information can assist doctors in making decisions about treatment plans, monitoring strategies, and early interventions to prevent further kidney damage.)\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 What features might help predict the target?\n",
    "\n",
    "*Based on your intuition and domain knowledge, what columns do you think will be most important?*\n",
    "\n",
    "**Your answer:**\n",
    "\n",
    "[GFR is the primary indicator of kidney function,but several other features in the dataset can help predict CKD stage. These include serum creatinine, blood urea nitrogen (BUN), protein in urine, potassium levels, blood pressure, age, and glucose levels. These features are important because they either directly measure how well the kidneys filter waste or show how the body is affected when kidney function declines.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Dataset Overview\n",
    "\n",
    "### 2.1 Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 5,000 rows, 11 columns\n",
      "\n",
      "Column names:\n",
      "['Creatinine', 'BUN', 'GFR', 'Urine_Output', 'Diabetes', 'Hypertension', 'Age', 'Protein_in_Urine', 'Water_Intake', 'Medication', 'CKD_Status']\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# Update the path to match your file name\n",
    "df = pd.read_csv('../data/raw/kidney_dataset.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Dataset shape: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order for me to provide the stages numerically, I had to add the code below based on the GFR number. \n",
    "\n",
    "def determine_ckd_stage(gfr):\n",
    "    if gfr >= 90:\n",
    "        return 1\n",
    "    elif gfr >= 60:\n",
    "        return 2\n",
    "    elif gfr >= 30:\n",
    "        return 3\n",
    "    elif gfr >= 15:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "df[\"CKD Stage\"] = df[\"GFR\"].apply(determine_ckd_stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>BUN</th>\n",
       "      <th>GFR</th>\n",
       "      <th>Urine_Output</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Age</th>\n",
       "      <th>Protein_in_Urine</th>\n",
       "      <th>Water_Intake</th>\n",
       "      <th>Medication</th>\n",
       "      <th>CKD_Status</th>\n",
       "      <th>CKD Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788803</td>\n",
       "      <td>8.386869</td>\n",
       "      <td>102.161787</td>\n",
       "      <td>1632.649387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.682074</td>\n",
       "      <td>106.700203</td>\n",
       "      <td>1.570370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.413970</td>\n",
       "      <td>53.688796</td>\n",
       "      <td>50.071257</td>\n",
       "      <td>935.540516</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.122208</td>\n",
       "      <td>410.008362</td>\n",
       "      <td>3.425287</td>\n",
       "      <td>ACE Inhibitor</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647645</td>\n",
       "      <td>7.466540</td>\n",
       "      <td>89.451831</td>\n",
       "      <td>1774.553846</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.832284</td>\n",
       "      <td>123.336925</td>\n",
       "      <td>1.123301</td>\n",
       "      <td>Diuretic</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795508</td>\n",
       "      <td>12.516821</td>\n",
       "      <td>99.872180</td>\n",
       "      <td>2360.602980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.391900</td>\n",
       "      <td>116.098870</td>\n",
       "      <td>3.086846</td>\n",
       "      <td>ACE Inhibitor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.869010</td>\n",
       "      <td>19.855960</td>\n",
       "      <td>86.110182</td>\n",
       "      <td>1987.750901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.689515</td>\n",
       "      <td>55.668760</td>\n",
       "      <td>2.174980</td>\n",
       "      <td>ARB</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Creatinine        BUN         GFR  Urine_Output  Diabetes  Hypertension  \\\n",
       "0    0.788803   8.386869  102.161787   1632.649387         0             0   \n",
       "1    3.413970  53.688796   50.071257    935.540516         1             0   \n",
       "2    0.647645   7.466540   89.451831   1774.553846         1             1   \n",
       "3    0.795508  12.516821   99.872180   2360.602980         0             0   \n",
       "4    0.869010  19.855960   86.110182   1987.750901         0             1   \n",
       "\n",
       "         Age  Protein_in_Urine  Water_Intake     Medication  CKD_Status  \\\n",
       "0  27.682074        106.700203      1.570370            NaN           0   \n",
       "1  33.122208        410.008362      3.425287  ACE Inhibitor           1   \n",
       "2  55.832284        123.336925      1.123301       Diuretic           0   \n",
       "3  32.391900        116.098870      3.086846  ACE Inhibitor           0   \n",
       "4  66.689515         55.668760      2.174980            ARB           0   \n",
       "\n",
       "   CKD Stage  \n",
       "0          1  \n",
       "1          3  \n",
       "2          2  \n",
       "3          1  \n",
       "4          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: View the first 5 rows of your dataframe\n",
    "#\n",
    "# Hint: Use .head()\n",
    "\n",
    "# YOUR CODE HERE: \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>BUN</th>\n",
       "      <th>GFR</th>\n",
       "      <th>Urine_Output</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Age</th>\n",
       "      <th>Protein_in_Urine</th>\n",
       "      <th>Water_Intake</th>\n",
       "      <th>Medication</th>\n",
       "      <th>CKD_Status</th>\n",
       "      <th>CKD Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4.048737</td>\n",
       "      <td>53.094020</td>\n",
       "      <td>24.964596</td>\n",
       "      <td>1179.120228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64.910042</td>\n",
       "      <td>2846.781763</td>\n",
       "      <td>3.403640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.787392</td>\n",
       "      <td>7.598859</td>\n",
       "      <td>94.228637</td>\n",
       "      <td>2029.623102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.365980</td>\n",
       "      <td>56.600073</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>ACE Inhibitor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.177967</td>\n",
       "      <td>10.198228</td>\n",
       "      <td>89.099101</td>\n",
       "      <td>2463.843638</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.207777</td>\n",
       "      <td>88.090385</td>\n",
       "      <td>2.238708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1.189794</td>\n",
       "      <td>12.446732</td>\n",
       "      <td>90.539937</td>\n",
       "      <td>1851.314122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.270049</td>\n",
       "      <td>64.837267</td>\n",
       "      <td>3.188672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1.000078</td>\n",
       "      <td>11.804883</td>\n",
       "      <td>91.697611</td>\n",
       "      <td>2056.462819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.782239</td>\n",
       "      <td>134.514375</td>\n",
       "      <td>3.755283</td>\n",
       "      <td>ACE Inhibitor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Creatinine        BUN        GFR  Urine_Output  Diabetes  Hypertension  \\\n",
       "4995    4.048737  53.094020  24.964596   1179.120228         1             1   \n",
       "4996    0.787392   7.598859  94.228637   2029.623102         0             1   \n",
       "4997    1.177967  10.198228  89.099101   2463.843638         0             1   \n",
       "4998    1.189794  12.446732  90.539937   1851.314122         1             0   \n",
       "4999    1.000078  11.804883  91.697611   2056.462819         0             0   \n",
       "\n",
       "            Age  Protein_in_Urine  Water_Intake     Medication  CKD_Status  \\\n",
       "4995  64.910042       2846.781763      3.403640            NaN           1   \n",
       "4996  49.365980         56.600073      1.759214  ACE Inhibitor           0   \n",
       "4997  47.207777         88.090385      2.238708            NaN           0   \n",
       "4998  31.270049         64.837267      3.188672            NaN           0   \n",
       "4999  61.782239        134.514375      3.755283  ACE Inhibitor           0   \n",
       "\n",
       "      CKD Stage  \n",
       "4995          4  \n",
       "4996          1  \n",
       "4997          2  \n",
       "4998          1  \n",
       "4999          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: View the last 5 rows of your dataframe\n",
    "#\n",
    "# Hint: Use .tail()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Types and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Creatinine        5000 non-null   float64\n",
      " 1   BUN               5000 non-null   float64\n",
      " 2   GFR               5000 non-null   float64\n",
      " 3   Urine_Output      5000 non-null   float64\n",
      " 4   Diabetes          5000 non-null   int64  \n",
      " 5   Hypertension      5000 non-null   int64  \n",
      " 6   Age               5000 non-null   float64\n",
      " 7   Protein_in_Urine  5000 non-null   float64\n",
      " 8   Water_Intake      5000 non-null   float64\n",
      " 9   Medication        2013 non-null   object \n",
      " 10  CKD_Status        5000 non-null   int64  \n",
      " 11  CKD Stage         5000 non-null   int64  \n",
      "dtypes: float64(7), int64(4), object(1)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display info about your dataframe (data types, non-null counts)\n",
    "#\n",
    "# Hint: Use .info()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>BUN</th>\n",
       "      <th>GFR</th>\n",
       "      <th>Urine_Output</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Age</th>\n",
       "      <th>Protein_in_Urine</th>\n",
       "      <th>Water_Intake</th>\n",
       "      <th>CKD_Status</th>\n",
       "      <th>CKD Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.994088</td>\n",
       "      <td>30.780063</td>\n",
       "      <td>73.251883</td>\n",
       "      <td>1664.302800</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>50.048733</td>\n",
       "      <td>537.053851</td>\n",
       "      <td>2.504335</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>2.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.027013</td>\n",
       "      <td>31.148341</td>\n",
       "      <td>31.972399</td>\n",
       "      <td>599.384655</td>\n",
       "      <td>0.455637</td>\n",
       "      <td>0.484986</td>\n",
       "      <td>14.492020</td>\n",
       "      <td>817.510451</td>\n",
       "      <td>0.868925</td>\n",
       "      <td>0.440306</td>\n",
       "      <td>1.359489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.600040</td>\n",
       "      <td>7.007732</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>400.502554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>50.010471</td>\n",
       "      <td>1.000810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.801333</td>\n",
       "      <td>11.367599</td>\n",
       "      <td>53.036801</td>\n",
       "      <td>1105.890821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.190016</td>\n",
       "      <td>83.692533</td>\n",
       "      <td>1.744138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.007629</td>\n",
       "      <td>15.878566</td>\n",
       "      <td>89.555882</td>\n",
       "      <td>1814.499690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.942824</td>\n",
       "      <td>119.492591</td>\n",
       "      <td>2.511710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.163997</td>\n",
       "      <td>40.636666</td>\n",
       "      <td>93.989273</td>\n",
       "      <td>2146.441778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.761132</td>\n",
       "      <td>588.428649</td>\n",
       "      <td>3.268812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.996428</td>\n",
       "      <td>119.931652</td>\n",
       "      <td>105.451432</td>\n",
       "      <td>2499.939696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>2997.724192</td>\n",
       "      <td>3.998043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Creatinine          BUN          GFR  Urine_Output     Diabetes  \\\n",
       "count  5000.000000  5000.000000  5000.000000   5000.000000  5000.000000   \n",
       "mean      1.994088    30.780063    73.251883   1664.302800     0.294000   \n",
       "std       2.027013    31.148341    31.972399    599.384655     0.455637   \n",
       "min       0.600040     7.007732     5.000000    400.502554     0.000000   \n",
       "25%       0.801333    11.367599    53.036801   1105.890821     0.000000   \n",
       "50%       1.007629    15.878566    89.555882   1814.499690     0.000000   \n",
       "75%       2.163997    40.636666    93.989273   2146.441778     1.000000   \n",
       "max       7.996428   119.931652   105.451432   2499.939696     1.000000   \n",
       "\n",
       "       Hypertension          Age  Protein_in_Urine  Water_Intake   CKD_Status  \\\n",
       "count   5000.000000  5000.000000       5000.000000   5000.000000  5000.000000   \n",
       "mean       0.378200    50.048733        537.053851      2.504335     0.263000   \n",
       "std        0.484986    14.492020        817.510451      0.868925     0.440306   \n",
       "min        0.000000    18.000000         50.010471      1.000810     0.000000   \n",
       "25%        0.000000    40.190016         83.692533      1.744138     0.000000   \n",
       "50%        0.000000    49.942824        119.492591      2.511710     0.000000   \n",
       "75%        1.000000    59.761132        588.428649      3.268812     1.000000   \n",
       "max        1.000000    90.000000       2997.724192      3.998043     1.000000   \n",
       "\n",
       "         CKD Stage  \n",
       "count  5000.000000  \n",
       "mean      2.073200  \n",
       "std       1.359489  \n",
       "min       1.000000  \n",
       "25%       1.000000  \n",
       "50%       2.000000  \n",
       "75%       3.000000  \n",
       "max       5.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Get summary statistics for numerical columns\n",
    "#\n",
    "# Hint: Use .describe()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ACE Inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Medication\n",
       "count            2013\n",
       "unique              3\n",
       "top     ACE Inhibitor\n",
       "freq             1013"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Get summary statistics for categorical columns\n",
    "#\n",
    "# Hint: Use .describe(include='object')\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.describe(include='object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dataset Description\n",
    "\n",
    "*After looking at the data above, describe your dataset in your own words.*\n",
    "\n",
    "**Questions to answer:**\n",
    "- Where did this data come from? (Kaggle link, source)\n",
    "- What does each row represent?\n",
    "- How many features do you have?\n",
    "- What types of features do you have? (numerical, categorical)\n",
    "\n",
    "**Your description:**\n",
    "\n",
    "[Write your description here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Initial EDA\n",
    "\n",
    "### 3.1 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your target variable\n",
    "TARGET = 'your_target_column'  # <-- UPDATE THIS!\n",
    "\n",
    "# Basic statistics of target\n",
    "print(f\"Target Variable: {TARGET}\")\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(df[TARGET].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df[TARGET].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel(TARGET)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(f'Distribution of {TARGET}')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df[TARGET].dropna())\n",
    "axes[1].set_ylabel(TARGET)\n",
    "axes[1].set_title(f'Box Plot of {TARGET}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check skewness\n",
    "skewness = df[TARGET].skew()\n",
    "print(f\"\\nSkewness: {skewness:.2f}\")\n",
    "if abs(skewness) > 1:\n",
    "    print(\"→ Target is highly skewed. Consider log transform in feature engineering.\")\n",
    "elif abs(skewness) > 0.5:\n",
    "    print(\"→ Target is moderately skewed.\")\n",
    "else:\n",
    "    print(\"→ Target is approximately symmetric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for duplicate rows in your dataframe\n",
    "#\n",
    "# Steps:\n",
    "# 1. Count how many duplicate rows exist using df.duplicated().sum()\n",
    "# 2. Print the count and the percentage of duplicates\n",
    "#\n",
    "# Expected output format:\n",
    "# \"Duplicate rows: X,XXX (X.XX%)\"\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a summary of missing values\n",
    "#\n",
    "# Steps:\n",
    "# 1. Calculate missing count for each column: df.isnull().sum()\n",
    "# 2. Calculate missing percentage: (df.isnull().sum() / len(df)) * 100\n",
    "# 3. Create a DataFrame with 'Missing Count' and 'Missing %' columns\n",
    "# 4. Sort by 'Missing %' descending\n",
    "# 5. Display only columns that have missing values\n",
    "#\n",
    "# Hint: You can create a DataFrame with pd.DataFrame({'col1': series1, 'col2': series2})\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values (if any)\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_cols = missing_df[missing_df['Missing Count'] > 0]\n",
    "    colors = ['red' if pct > 50 else 'orange' if pct > 20 else 'steelblue' \n",
    "              for pct in missing_cols['Missing %']]\n",
    "    plt.barh(missing_cols.index, missing_cols['Missing %'], color=colors)\n",
    "    plt.xlabel('Missing Percentage')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.axvline(x=50, color='red', linestyle='--', alpha=0.5, label='50% threshold')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Recommendation\n",
    "    high_missing = missing_cols[missing_cols['Missing %'] > 50]\n",
    "    if len(high_missing) > 0:\n",
    "        print(f\"\\n⚠️ Columns with >50% missing (consider dropping): {high_missing.index.tolist()}\")\n",
    "else:\n",
    "    print(\"✓ No missing values in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Initial Observations\n",
    "\n",
    "*Based on your initial exploration, what do you notice?*\n",
    "\n",
    "**Questions to consider:**\n",
    "- Is your target variable normally distributed or skewed?\n",
    "- Are there any obvious outliers in the target?\n",
    "- How much missing data do you have to deal with?\n",
    "- Are there any duplicate rows?\n",
    "- Any surprises or interesting findings?\n",
    "\n",
    "**Your observations:**\n",
    "\n",
    "[Write your observations here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Checkpoint 1 Submission Instructions\n",
    "\n",
    "**Congratulations!** You've completed Checkpoint 1. Before moving on, let's commit your work and submit.\n",
    "\n",
    "### Step 1: Save This Notebook\n",
    "- File → Save (or Ctrl+S / Cmd+S)\n",
    "\n",
    "### Step 2: Commit to GitHub\n",
    "Open your terminal and run these commands:\n",
    "\n",
    "```bash\n",
    "# Navigate to your project folder (if not already there)\n",
    "cd path/to/your/capstone-project\n",
    "\n",
    "# Stage your notebook and data\n",
    "git add notebooks/01_problem_statement_and_eda.ipynb\n",
    "git add data/raw/\n",
    "\n",
    "# Commit with a meaningful message\n",
    "git commit -m \"Complete Checkpoint 1: Problem statement and initial EDA\"\n",
    "\n",
    "# Push to GitHub\n",
    "git push\n",
    "```\n",
    "\n",
    "### Step 3: Submit to Canvas\n",
    "1. Go to the Checkpoint 1 assignment on Canvas\n",
    "2. Submit the link to your GitHub repository\n",
    "3. Make sure your repo shows your latest commit!\n",
    "\n",
    "### Step 4: Continue to Checkpoint 2\n",
    "Now proceed to **Section 4** below to continue with your complete EDA, data cleaning, and feature engineering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# CHECKPOINT 2 (Due: Feb 8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Complete EDA\n",
    "\n",
    "### 4.1 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a list of numerical columns (excluding the target)\n",
    "#\n",
    "# Steps:\n",
    "# 1. Use df.select_dtypes(include=[np.number]) to get numerical columns\n",
    "# 2. Get the column names as a list with .columns.tolist()\n",
    "# 3. Remove TARGET from the list if it's in there\n",
    "# 4. Print the count and list of numerical features\n",
    "#\n",
    "# Store result in: numerical_cols\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 and n_cols == 1 else axes\n",
    "\n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        axes[i].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].set_xlabel('')\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(len(numerical_cols), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical features found (besides target).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a list of categorical columns and explore their values\n",
    "#\n",
    "# Steps:\n",
    "# 1. Use df.select_dtypes(include=['object', 'category']) to get categorical columns\n",
    "# 2. Get the column names as a list\n",
    "# 3. Print the count and list of categorical features\n",
    "# 4. For each categorical column, print:\n",
    "#    - Number of unique values: df[col].nunique()\n",
    "#    - Top 10 value counts: df[col].value_counts().head(10)\n",
    "#\n",
    "# Store result in: categorical_cols\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features (for columns with reasonable number of categories)\n",
    "cat_cols_to_plot = [col for col in categorical_cols if df[col].nunique() <= 10]\n",
    "\n",
    "if cat_cols_to_plot:\n",
    "    n_cols = 2\n",
    "    n_rows = (len(cat_cols_to_plot) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if len(cat_cols_to_plot) == 1 else axes\n",
    "    \n",
    "    for i, col in enumerate(cat_cols_to_plot):\n",
    "        df[col].value_counts().plot(kind='bar', ax=axes[i], edgecolor='black')\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for j in range(len(cat_cols_to_plot), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No categorical columns with ≤10 unique values to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Categorical Features vs Target\n",
    "\n",
    "*How does the target variable differ across categories?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots: Target by categorical features\n",
    "cat_cols_to_analyze = [col for col in categorical_cols if df[col].nunique() <= 8]\n",
    "\n",
    "if cat_cols_to_analyze:\n",
    "    for col in cat_cols_to_analyze[:4]:  # Limit to first 4 for readability\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Order by median target value\n",
    "        order = df.groupby(col)[TARGET].median().sort_values().index\n",
    "        \n",
    "        sns.boxplot(data=df, x=col, y=TARGET, order=order)\n",
    "        plt.title(f'{TARGET} by {col}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show mean target by category\n",
    "        print(f\"\\nMean {TARGET} by {col}:\")\n",
    "        print(df.groupby(col)[TARGET].agg(['mean', 'median', 'count']).sort_values('mean', ascending=False))\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "else:\n",
    "    print(\"No suitable categorical columns for this analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and visualize a correlation matrix\n",
    "#\n",
    "# Steps:\n",
    "# 1. Create a list of columns: numerical_cols + [TARGET]\n",
    "# 2. Calculate the correlation matrix: df[columns].corr()\n",
    "# 3. Create a heatmap using sns.heatmap()\n",
    "#\n",
    "# Heatmap parameters to use:\n",
    "# - annot=True (show numbers)\n",
    "# - cmap='coolwarm' (color scheme)\n",
    "# - center=0 (center colormap at 0)\n",
    "# - fmt='.2f' (2 decimal places)\n",
    "#\n",
    "# Store the correlation matrix in: correlation_matrix\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract and analyze correlations with the target variable\n",
    "#\n",
    "# Steps:\n",
    "# 1. Get the TARGET column from correlation_matrix\n",
    "# 2. Drop the TARGET's correlation with itself (it's always 1.0)\n",
    "# 3. Sort values in descending order\n",
    "# 4. Print the correlations\n",
    "# 5. Identify strong correlations (absolute value > 0.5)\n",
    "#\n",
    "# Store result in: target_correlations\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations with target\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if c > 0 else 'red' for c in target_correlations]\n",
    "target_correlations.plot(kind='barh', color=colors)\n",
    "plt.xlabel('Correlation')\n",
    "plt.title(f'Feature Correlations with {TARGET}')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Feature vs Target Relationships\n",
    "\n",
    "*Create scatter plots for your most promising numerical features against the target.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top correlated features to plot\n",
    "top_features = target_correlations.abs().sort_values(ascending=False).head(4).index.tolist()\n",
    "\n",
    "if len(top_features) > 0:\n",
    "    n_features = min(4, len(top_features))\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(top_features[:n_features]):\n",
    "        axes[i].scatter(df[feature], df[TARGET], alpha=0.5)\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel(TARGET)\n",
    "        corr = df[feature].corr(df[TARGET])\n",
    "        axes[i].set_title(f'{feature} vs {TARGET} (r={corr:.2f})')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(n_features, 4):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical features to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Additional Exploration (Your Choice!)\n",
    "\n",
    "The sections above provide a foundation, but every dataset is unique. Use the cells below to explore additional aspects of YOUR data that you think are important.\n",
    "\n",
    "**Ideas for additional exploration:**\n",
    "- Violin plots for categorical vs target (shows distribution shape)\n",
    "- Look at feature interactions (e.g., does the relationship between X and Y change based on Z?)\n",
    "- Explore geographic patterns (if you have location data)\n",
    "- Create pair plots for key features (`sns.pairplot()`)\n",
    "- Analyze distributions across different subgroups\n",
    "- Look for data quality issues specific to your dataset\n",
    "- Check for nonsensical values (negative prices, impossible ages, etc.)\n",
    "\n",
    "**Remember:** The best insights often come from curiosity-driven exploration, not just following a template. What questions do YOU have about your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ADDITIONAL EDA CODE HERE\n",
    "# Add as many cells as you need - don't be limited by this template!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More exploration...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What additional insights did you discover?**\n",
    "\n",
    "[Describe any additional findings from your custom exploration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 EDA Insights Summary\n",
    "\n",
    "*Summarize your key findings from the EDA.*\n",
    "\n",
    "**Questions to answer:**\n",
    "- Which features are most correlated with your target?\n",
    "- Which categorical features show the biggest differences in target?\n",
    "- Are there any features that seem unimportant?\n",
    "- Did you discover any interesting patterns or relationships?\n",
    "- Are there any concerns about the data (outliers, skewness, etc.)?\n",
    "\n",
    "**Your summary:**\n",
    "\n",
    "[Write your summary here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Data Cleaning\n",
    "\n",
    "### 5.1 Decide What to Drop\n",
    "\n",
    "Before cleaning, decide which columns to remove entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a copy of your dataframe for cleaning\n",
    "#\n",
    "# Why? We want to preserve the original data in case we need to go back.\n",
    "# Never modify your original dataframe directly!\n",
    "#\n",
    "# Store in: df_clean\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n",
    "\n",
    "print(f\"Starting shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to potentially drop\n",
    "print(\"Columns to consider dropping:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. High missing rate\n",
    "high_missing = missing_df[missing_df['Missing %'] > 50].index.tolist()\n",
    "print(f\"\\n1. >50% missing values: {high_missing}\")\n",
    "\n",
    "# 2. ID/index columns (no predictive value)\n",
    "potential_ids = [col for col in df_clean.columns \n",
    "                 if 'id' in col.lower() or 'index' in col.lower() or 'url' in col.lower()]\n",
    "print(f\"\\n2. Potential ID/URL columns: {potential_ids}\")\n",
    "\n",
    "# 3. High cardinality categorical (too many unique values)\n",
    "high_cardinality = [col for col in categorical_cols if df_clean[col].nunique() > 100]\n",
    "print(f\"\\n3. High cardinality (>100 unique): {high_cardinality}\")\n",
    "\n",
    "# 4. Low variance (same value in most rows)\n",
    "low_variance = [col for col in df_clean.columns \n",
    "                if df_clean[col].value_counts(normalize=True).iloc[0] > 0.95]\n",
    "print(f\"\\n4. Low variance (>95% same value): {low_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "# TODO: Decide which columns to drop based on the analysis above\n",
    "# IMPORTANT: Don't just copy all suggestions - think about each one!\n",
    "\n",
    "columns_to_drop = [\n",
    "    # Add column names to drop here, e.g.:\n",
    "    # 'id',\n",
    "    # 'url',\n",
    "]\n",
    "\n",
    "if columns_to_drop:\n",
    "    df_clean = df_clean.drop(columns=columns_to_drop)\n",
    "    print(f\"Dropped {len(columns_to_drop)} columns: {columns_to_drop}\")\n",
    "    print(f\"New shape: {df_clean.shape}\")\n",
    "else:\n",
    "    print(\"No columns dropped. Update the list above if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain which columns you dropped and why:**\n",
    "\n",
    "[Describe your reasoning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Handle Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove duplicate rows from df_clean\n",
    "#\n",
    "# Steps:\n",
    "# 1. Store the row count before: len(df_clean)\n",
    "# 2. Use df_clean.drop_duplicates() to remove duplicates (assign back to df_clean)\n",
    "# 3. Store the row count after\n",
    "# 4. Print how many duplicates were removed\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in cleaned dataframe\n",
    "print(\"Missing values before handling:\")\n",
    "missing_now = df_clean.isnull().sum()\n",
    "missing_now = missing_now[missing_now > 0].sort_values(ascending=False)\n",
    "print(missing_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# TODO: Add your missing value handling code here\n",
    "# \n",
    "# STRATEGIES:\n",
    "# - Numerical columns: use median (robust to outliers) or mean\n",
    "# - Categorical columns: use mode or 'Unknown'\n",
    "# - Drop rows if missing target variable\n",
    "#\n",
    "# Examples:\n",
    "# df_clean['column'] = df_clean['column'].fillna(df_clean['column'].median())\n",
    "# df_clean['column'] = df_clean['column'].fillna('Unknown')\n",
    "# df_clean = df_clean.dropna(subset=[TARGET])  # Don't predict with missing target!\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify missing values are handled\n",
    "remaining_missing = df_clean.isnull().sum().sum()\n",
    "print(f\"Missing values after cleaning: {remaining_missing}\")\n",
    "\n",
    "if remaining_missing > 0:\n",
    "    print(\"\\n⚠️ Still have missing values in:\")\n",
    "    print(df_clean.isnull().sum()[df_clean.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your missing value strategy:**\n",
    "\n",
    "[Describe what you did for each column and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Handle Outliers (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers using IQR method\n",
    "def find_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    n_outliers = len(data[(data[column] < lower_bound) | (data[column] > upper_bound)])\n",
    "    return n_outliers, lower_bound, upper_bound\n",
    "\n",
    "# Get current numerical columns\n",
    "current_numerical = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Outlier analysis:\")\n",
    "print(\"=\"*60)\n",
    "for col in current_numerical:\n",
    "    n_outliers, lower, upper = find_outliers_iqr(df_clean, col)\n",
    "    if n_outliers > 0:\n",
    "        pct = n_outliers / len(df_clean) * 100\n",
    "        print(f\"{col}: {n_outliers:,} outliers ({pct:.1f}%) | bounds: [{lower:.2f}, {upper:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers (if needed)\n",
    "# TODO: Add your outlier handling code here if needed\n",
    "#\n",
    "# STRATEGIES:\n",
    "# - Remove rows with outliers (be careful - losing data)\n",
    "# - Cap/clip values at bounds\n",
    "# - Keep them (if they're valid data points)\n",
    "#\n",
    "# Examples:\n",
    "# df_clean = df_clean[df_clean['price'] > 0]  # Remove invalid prices\n",
    "# df_clean = df_clean[df_clean['price'] < 500000]  # Remove extreme prices\n",
    "# df_clean['column'] = df_clean['column'].clip(lower=0, upper=upper_bound)\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your outlier handling strategy (or why you kept them):**\n",
    "\n",
    "[Describe what you did and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Data Type Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current data types\n",
    "print(\"Current data types:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix any data type issues\n",
    "# TODO: Add your data type corrections here if needed\n",
    "#\n",
    "# Examples:\n",
    "# df_clean['year'] = df_clean['year'].astype(int)\n",
    "# df_clean['date_column'] = pd.to_datetime(df_clean['date_column'])\n",
    "# df_clean['category'] = df_clean['category'].astype('category')\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Feature Engineering\n",
    "\n",
    "Feature engineering is where you can really add value! The sections below cover common techniques, but feel free to go beyond these basics.\n",
    "\n",
    "### 6.1 Create New Features (if applicable)\n",
    "\n",
    "**Common feature engineering techniques:**\n",
    "- **Ratios/interactions:** Combine existing features (e.g., price per square foot)\n",
    "- **Log transforms:** Reduce skewness in highly skewed features\n",
    "- **Binning:** Convert continuous variables to categories\n",
    "- **Text features:** Extract length, word counts, etc. from text\n",
    "- **Domain-specific:** Features that make sense for your specific problem\n",
    "\n",
    "Think about what would help YOUR specific prediction problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "# TODO: Add your feature engineering code here\n",
    "#\n",
    "# Examples:\n",
    "# df_clean['price_per_sqft'] = df_clean['price'] / df_clean['sqft']\n",
    "# df_clean['log_price'] = np.log1p(df_clean['price'])\n",
    "# df_clean['age'] = 2026 - df_clean['year']\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your new features:**\n",
    "\n",
    "[Describe what features you created and why they might help predict the target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify categorical columns that need encoding\n",
    "#\n",
    "# Steps:\n",
    "# 1. Get categorical columns using select_dtypes(include=['object', 'category'])\n",
    "# 2. For each column, print:\n",
    "#    - Column name\n",
    "#    - Number of unique values: .nunique()\n",
    "#    - Recommendation: \"one-hot encoding\" if <= 10 unique, else \"consider label encoding or dropping\"\n",
    "#\n",
    "# Store in: cat_cols\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "# TODO: Add your encoding code here\n",
    "#\n",
    "# STRATEGIES:\n",
    "# - One-hot encoding: for low cardinality (< 10 unique values)\n",
    "# - Label encoding: for ordinal data or high cardinality\n",
    "# - Target encoding: advanced technique (be careful of data leakage)\n",
    "#\n",
    "# Examples:\n",
    "# One-hot encoding:\n",
    "# df_clean = pd.get_dummies(df_clean, columns=['category_col'], drop_first=True)\n",
    "#\n",
    "# Label encoding:\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# df_clean['encoded_col'] = le.fit_transform(df_clean['category_col'])\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your encoding strategy:**\n",
    "\n",
    "[Describe what encoding methods you used and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Additional Feature Engineering (Your Choice!)\n",
    "\n",
    "Every dataset has unique opportunities for feature engineering. What else makes sense for YOUR data?\n",
    "\n",
    "**Think about:**\n",
    "- What domain knowledge can you apply?\n",
    "- Are there any feature interactions that might be predictive?\n",
    "- Can you create meaningful groups or categories?\n",
    "- Would polynomial features help capture non-linear relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ADDITIONAL FEATURE ENGINEERING CODE HERE\n",
    "# Add as many cells as you need!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your additional feature engineering:**\n",
    "\n",
    "[Describe any additional features you created and your reasoning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Feature Scaling (Preparation)\n",
    "\n",
    "We'll do actual scaling in the modeling notebook, but let's check which features might need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify numerical features and check their ranges\n",
    "#\n",
    "# Steps:\n",
    "# 1. Get numerical columns from df_clean (excluding TARGET)\n",
    "# 2. For each column, print the min, max, and range\n",
    "#\n",
    "# This helps you understand if features need scaling (different scales = need scaling)\n",
    "#\n",
    "# Store in: numerical_features\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Final Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data quality checks before saving\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL DATA QUALITY CHECKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. Shape: {df_clean.shape[0]:,} rows, {df_clean.shape[1]} columns\")\n",
    "print(f\"   (Started with {df.shape[0]:,} rows, {df.shape[1]} columns)\")\n",
    "\n",
    "print(f\"\\n2. Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n3. Duplicate rows: {df_clean.duplicated().sum()}\")\n",
    "\n",
    "print(f\"\\n4. Target variable '{TARGET}':\")\n",
    "print(f\"   - Min: {df_clean[TARGET].min():.2f}\")\n",
    "print(f\"   - Max: {df_clean[TARGET].max():.2f}\")\n",
    "print(f\"   - Mean: {df_clean[TARGET].mean():.2f}\")\n",
    "\n",
    "# Check for data leakage red flags\n",
    "print(f\"\\n5. Data types:\")\n",
    "print(f\"   - Numerical: {len(df_clean.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"   - Categorical: {len(df_clean.select_dtypes(include=['object', 'category']).columns)}\")\n",
    "\n",
    "remaining_cats = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if remaining_cats:\n",
    "    print(f\"\\n⚠️ Still have categorical columns: {remaining_cats}\")\n",
    "    print(\"   Make sure these are encoded before modeling!\")\n",
    "else:\n",
    "    print(\"\\n✓ All features are numerical. Ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check of cleaned data\n",
    "print(\"Final cleaned dataset:\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"\\nColumns ({len(df_clean.columns)}):\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df_clean.to_csv('../data/processed/cleaned_data.csv', index=False)\n",
    "print(\"✓ Cleaned data saved to ../data/processed/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Feature Engineering Summary\n",
    "\n",
    "*Summarize all the data cleaning and feature engineering you performed.*\n",
    "\n",
    "**Checklist:**\n",
    "- [ ] Columns dropped (with justification)\n",
    "- [ ] Duplicate rows removed\n",
    "- [ ] Missing values handled\n",
    "- [ ] Outliers addressed (or documented why not)\n",
    "- [ ] Data types corrected\n",
    "- [ ] New features created (if applicable)\n",
    "- [ ] Categorical variables encoded\n",
    "- [ ] Data saved to processed folder\n",
    "\n",
    "**Summary of changes:**\n",
    "\n",
    "[Write a thorough summary of everything you did to clean and transform the data]\n",
    "\n",
    "**Final feature list for modeling:**\n",
    "\n",
    "[List all the features you'll use in your models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Checkpoint 2 Submission Instructions\n",
    "\n",
    "**Congratulations!** You've completed Checkpoint 2 (EDA, Data Cleaning, and Feature Engineering).\n",
    "\n",
    "### Step 1: Save This Notebook\n",
    "- File → Save (or Ctrl+S / Cmd+S)\n",
    "\n",
    "### Step 2: Commit to GitHub\n",
    "\n",
    "```bash\n",
    "# Stage your changes\n",
    "git add notebooks/01_problem_statement_and_eda.ipynb\n",
    "git add data/processed/\n",
    "\n",
    "# Commit with a meaningful message\n",
    "git commit -m \"Complete Checkpoint 2: EDA, data cleaning, and feature engineering\"\n",
    "\n",
    "# Push to GitHub\n",
    "git push\n",
    "```\n",
    "\n",
    "### Step 3: Submit to Canvas\n",
    "1. Go to the Checkpoint 2 assignment on Canvas\n",
    "2. Submit the link to your GitHub repository\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You're ready to move on to **Notebook 02: Regression Model**!\n",
    "\n",
    "In that notebook, you'll:\n",
    "1. Load your cleaned data\n",
    "2. Split into train/test sets\n",
    "3. Build and evaluate regression models\n",
    "4. Save your best model\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
